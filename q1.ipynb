{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=red>HW02-q1 Vision Course, Panorama</font>\n",
    "This is the notebook for **q1.py** that is the implementation of **Video Panorama and Processing**. <br>\n",
    "The code is written by **Asal Mehradfar** with student number **96105434**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=orange>Description</font>\n",
    "\n",
    "*   I used the images with their best resolution in the first step, but\n",
    "for the other parts running the codes took a long time on my 8 RAM LAPTOP!\n",
    "So I decreased the resolution to quarter of the original one, haft each dimension.\n",
    "<br>\n",
    "*   At the 7th step, my results are not PERFECT. It can not detect the black cars\n",
    "which are far from the camera because of the similarity between their color\n",
    "and the background color, I mean the roads.\n",
    "* the zip file of the results are on my google drive in the link below:<br>\n",
    "[HW2_Results_96105434](https://drive.google.com/file/d/1E5dSZ2XjAk92DSmzueIJttUfc9p9QAc1/view?usp=sharing)\n",
    "*   I partitioned my code into 7 functions for the 7 parts like p1, p2,$$\\dots$$\n",
    "and also other useful functions. you can run each of them by uncommenting the main part.\n",
    "*   Pay attention that capture_frames() function makes some folders and frames\n",
    "that we need for the code, so make sure that you run them in the order of the main part.\n",
    "* The report of what I have done is written in each of the p1, p2, $$\\dots$$ functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=yellow>Imports</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "from scipy import stats\n",
    "from scipy import ndimage as nd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=yellow>Parameters</font>\n",
    "\n",
    "*   NUM_FRAMES = 900\n",
    "*   NUM_REF_FRAME = 450"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "NUM_FRAMES = 900\n",
    "NUM_REF_FRAME = 450\n",
    "R = 0.7\n",
    "MAX_ITERATIONS = 500"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=yellow>Functions</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    \"\"\"\n",
    "    Read the image file from the path and change it from BGR to RGB\n",
    "    pay attention that in open-cv colorful images are BGR **NOT** RGB\n",
    "\n",
    "    Inputs:\n",
    "    --> path: path for the image\n",
    "    Outputs:\n",
    "    ==> img: the RGB image\n",
    "    \"\"\"\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def plot_img(img, path=None):\n",
    "    \"\"\"\n",
    "    Plot a colorful image and save it if needed\n",
    "\n",
    "    Inputs:\n",
    "    --> img: the desired image\n",
    "    --> path: the default value is None, if it is given the image will be saved in the path\n",
    "    Outputs:\n",
    "    ==> Nothing, the image will be plotted\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    plt.imshow(img.astype(np.uint8))\n",
    "    plt.axis('off')\n",
    "    if path is not None:\n",
    "        fig.savefig(path)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def scaling_img(img):\n",
    "    \"\"\"\n",
    "    return the scaled image usually for saving\n",
    "\n",
    "    Inputs:\n",
    "    --> img: the desired image for scaling\n",
    "    Outputs:\n",
    "    ==> scaled_img: we assume that the minimum of the image is zero\n",
    "        so we scale it by division by its maximum and multiplying it by 255.0\n",
    "    \"\"\"\n",
    "    scaled_img = 255.0 * img / np.max(img)\n",
    "    return scaled_img\n",
    "\n",
    "def save_img(array, path):\n",
    "    \"\"\"\n",
    "    save the input image in the desired path\n",
    "\n",
    "    Inputs:\n",
    "    --> array: the array of an image\n",
    "    --> path: the desired path for saving the image\n",
    "    Outputs:\n",
    "    ==> Nothing, just saving the image\n",
    "    \"\"\"\n",
    "    scaled = scaling_img(array).astype(np.uint8)\n",
    "    img = Image.fromarray(scaled)\n",
    "    img.save(path)\n",
    "\n",
    "def capture_frames(path, save_path):\n",
    "    \"\"\"\n",
    "    Save NUM_FRAMES video frames in a folder\n",
    "\n",
    "    Inputs:\n",
    "    --> path: the filename of the video\n",
    "    --> save_path: the folder name of the saving frames\n",
    "    Outputs:\n",
    "    ==> Nothing, frames will be saved with 3 digit names\n",
    "    \"\"\"\n",
    "    os.mkdir(save_path)\n",
    "    vid = cv2.VideoCapture(path)\n",
    "\n",
    "    for i in range(NUM_FRAMES):\n",
    "        ret, frame = vid.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imwrite(save_path + '/' + str(i+1).zfill(3) + '.jpg', frame)\n",
    "\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def capture_frames_low_res():\n",
    "    \"\"\"\n",
    "    Save NUM_FRAMES video frames in a folder with low resolution\n",
    "    we down sample each dim to half of its previous form\n",
    "    so we decrease resolution to quarter of the original\n",
    "\n",
    "    Inputs:\n",
    "    --> Nothing\n",
    "    Outputs:\n",
    "    ==> Nothing, frames will be saved with 3 digit names\n",
    "    \"\"\"\n",
    "    os.mkdir('VideoFramesLowRes')\n",
    "    vid = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "    for i in range(NUM_FRAMES):\n",
    "        ret, frame = vid.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        size = (int(frame.shape[1] / 2), int(frame.shape[0] / 2))\n",
    "        new_frame = cv2.resize(frame, size, interpolation=cv2.INTER_AREA)\n",
    "        cv2.imwrite('VideoFramesLowRes/' + str(i+1).zfill(3) + '.jpg', new_frame)\n",
    "\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def find_homography(img1, img2):\n",
    "    \"\"\"\n",
    "    Finding match points between two images by RANSAC Algorithm\n",
    "\n",
    "    Inputs:\n",
    "    --> img1: the first desired image\n",
    "    --> img2: the second desired image\n",
    "    Outputs:\n",
    "    ==> H: the 3*3 homography matrix\n",
    "    \"\"\"\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # find all key points\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # find all matches\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # find good matches\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < R * n.distance:\n",
    "            good_matches.append([m])\n",
    "\n",
    "    kp1_match = [kp1[m[0].queryIdx] for m in good_matches]\n",
    "    kp2_match = [kp2[m[0].trainIdx] for m in good_matches]\n",
    "\n",
    "    # apply RANSAC\n",
    "    src_pts = np.float32([kp.pt for kp in kp1_match]).reshape(-1, 1, 2)\n",
    "    des_pts = np.float32([kp.pt for kp in kp2_match]).reshape(-1, 1, 2)\n",
    "    H,_ = cv2.findHomography(src_pts, des_pts, cv2.RANSAC, maxIters=MAX_ITERATIONS)\n",
    "\n",
    "    return np.linalg.inv(H)\n",
    "\n",
    "def perspective(img, H):\n",
    "    \"\"\"\n",
    "    computing the homography of the image with matrix H\n",
    "\n",
    "    Inputs:\n",
    "    --> img: the desired image\n",
    "    --> H: the homography matrix\n",
    "    Outputs:\n",
    "    ==> img_homography: the output image\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = corners_homography(img, H)\n",
    "    [x_offset, y_offset] = [-x_min, -y_min]\n",
    "    [x_size, y_size] = [x_max-x_min, y_max-y_min]\n",
    "    offset = np.array([[1, 0, x_offset], [0, 1, y_offset], [0, 0, 1]])\n",
    "    img_homography = cv2.warpPerspective(img, np.dot(offset, H), (x_size, y_size))\n",
    "    return img_homography\n",
    "\n",
    "def panorama_two_images(img1, img2, H):\n",
    "    \"\"\"\n",
    "    computing the panorama of two input images with matrix H on the second image\n",
    "    the first image will be up to the second one in the union\n",
    "\n",
    "    Inputs:\n",
    "    --> img1: the first desired image\n",
    "    --> img2: the second desired image\n",
    "    --> H: the homography matrix\n",
    "    Outputs:\n",
    "    ==> img: the output panorama image\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = corners_homography(img2, H)\n",
    "    [x_offset, y_offset] = [-x_min, -y_min]\n",
    "    [x_size, y_size] = [max(img1.shape[1] + max(0, x_offset), x_max-x_min),\n",
    "                        max(img1.shape[0] + max(0, y_offset), y_max-y_min)]\n",
    "    offset = np.array([[1, 0, x_offset], [0, 1, y_offset], [0, 0, 1]])\n",
    "    img = cv2.warpPerspective(img2, np.dot(offset, H), (x_size, y_size))\n",
    "    img[y_offset: img1.shape[0] + y_offset, x_offset: img1.shape[1] + x_offset, :] = img1\n",
    "    return img\n",
    "\n",
    "def corners_homography(img, H):\n",
    "    \"\"\"\n",
    "    computing the min and max of the corners of an image\n",
    "    after applying the homography matrix without offset\n",
    "    we use these points to find offset and size of the homography\n",
    "\n",
    "    Inputs:\n",
    "    --> img: the desired image\n",
    "    --> H: the homography matrix\n",
    "    Outputs:\n",
    "    ==> x_min: minimum x after homography\n",
    "    ==> y_min: minimum y after homography\n",
    "    ==> x_max: maximum x after homography\n",
    "    ==> y_max: maximum y after homography\n",
    "    \"\"\"\n",
    "    height, width, _ = img.shape\n",
    "    corners = [np.array([[0, 0, 1]]).transpose(),\n",
    "            np.array([[width-1, 0, 1]]).transpose(),\n",
    "            np.array([[0, height-1, 1]]).transpose(),\n",
    "            np.array([[width-1, height-1, 1]]).transpose()]\n",
    "    [x_min, y_min, x_max, y_max] = [-1 for _ in range(4)]\n",
    "    for c in corners:\n",
    "        m = np.matmul(H, c)\n",
    "        if x_min == -1:\n",
    "            [x_min, y_min, x_max, y_max] = [int(m[0] / m[2]),\n",
    "                                            int(m[1] / m[2]),\n",
    "                                            int(m[0] / m[2]),\n",
    "                                            int(m[1] / m[2])]\n",
    "        else:\n",
    "            [x_min, y_min, x_max, y_max] = [min(x_min, int(m[0] / m[2])),\n",
    "                                            min(y_min, int(m[1] / m[2])),\n",
    "                                            max(x_max, int(m[0] / m[2])),\n",
    "                                            max(y_max, int(m[1] / m[2]))]\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "def compute_H_to_450():\n",
    "    \"\"\"\n",
    "    computing the homography matrix for all the images to the reference image:\n",
    "    moving images less than 90 to 90 and then to 270 and at last 450,\n",
    "    moving images less than 270 and more than 90 to 270 and then 450,\n",
    "    moving images less than 630 and more than 270 directly to 450,\n",
    "    moving images less than 810 and more than 630 to 630 and then 450,\n",
    "    moving image more than 810 to 810 and then to 630 and at last 450.\n",
    "\n",
    "    Inputs:\n",
    "    --> Nothing\n",
    "    Outputs:\n",
    "    ==> H: a 900*3*3 matrix, each row is a homography matrix\n",
    "        for one of the frames to the reference image\n",
    "    \"\"\"\n",
    "    H = np.zeros((NUM_FRAMES, 3, 3))\n",
    "    ref_images, H[89, :, :], H[269, :, :], H[449, :, :], H[629, :, :], H[809, :, :] = compute_key_frames_H()\n",
    "\n",
    "    for i in tqdm.tqdm(range(NUM_FRAMES)):\n",
    "        if i == 89 or i == 269 or i == 449 or i == 629 or i == 809:\n",
    "            continue\n",
    "        elif i < 89:\n",
    "            H[i, :, :] = np.matmul(H[89, :, :], find_homography(ref_images[0],\n",
    "                            get_img('VideoFramesLowRes/' + str(i+1).zfill(3) +'.jpg')))\n",
    "        elif i<269:\n",
    "            H[i, :, :] = np.matmul(H[269, :, :], find_homography(ref_images[1],\n",
    "                            get_img('VideoFramesLowRes/' + str(i+1).zfill(3) +'.jpg')))\n",
    "        elif i<629:\n",
    "            H[i, :, :] = find_homography(ref_images[2],\n",
    "                            get_img('VideoFramesLowRes/' + str(i+1).zfill(3) +'.jpg'))\n",
    "        elif i<809:\n",
    "            H[i, :, :] = np.matmul(H[629, :, :], find_homography(ref_images[3],\n",
    "                            get_img('VideoFramesLowRes/' + str(i+1).zfill(3) +'.jpg')))\n",
    "        else:\n",
    "            H[i, :, :] = np.matmul(H[809, :, :], find_homography(ref_images[4],\n",
    "                            get_img('VideoFramesLowRes/' + str(i+1).zfill(3) +'.jpg')))\n",
    "\n",
    "    return H\n",
    "\n",
    "def compute_key_frames_H():\n",
    "    \"\"\"\n",
    "    computing key frames and homography of them\n",
    "\n",
    "    Inputs:\n",
    "    --> Nothing\n",
    "    Outputs:\n",
    "    ==> key_images: the list of 5 key frames\n",
    "    ==> H90: the homography of 90 to 450\n",
    "    ==> H180: the homography of 180 to 450\n",
    "    ==> H450: the homography of 450 to 450\n",
    "    ==> H630: the homography of 630 to 450\n",
    "    ==> H810: the homography of 810 to 450\n",
    "    \"\"\"\n",
    "    direc = 'VideoFramesLowRes/'\n",
    "    key_images = [\n",
    "        get_img(direc + '090.jpg'),\n",
    "        get_img(direc + '270.jpg'),\n",
    "        get_img(direc + '450.jpg'),\n",
    "        get_img(direc + '630.jpg'),\n",
    "        get_img(direc + '810.jpg')\n",
    "    ]\n",
    "    H90 = np.matmul(find_homography(key_images[2], key_images[1]), find_homography(key_images[1], key_images[0]))\n",
    "    H270 = find_homography(key_images[2], key_images[1])\n",
    "    H450 = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "    H630 = find_homography(key_images[2], key_images[3])\n",
    "    H810 = np.matmul(find_homography(key_images[2], key_images[3]), find_homography(key_images[3], key_images[4]))\n",
    "\n",
    "    return key_images, H90, H270, H450, H630, H810\n",
    "\n",
    "def video_corners_homography():\n",
    "    \"\"\"\n",
    "    computing the minimum and maximum coordinates for all the frames after homography to\n",
    "    the reference image 450\n",
    "\n",
    "    Inputs:\n",
    "    --> Nothing\n",
    "    Outputs:\n",
    "    ==> H: a 900*3*3 matrix, each row is a homography matrix\n",
    "        for one of the frames to the reference image\n",
    "    ==> x_min: minimum x after homography for all of the frames\n",
    "    ==> y_min: minimum y after homography for all of the frames\n",
    "    ==> x_max: maximum x after homography for all of the frames\n",
    "    ==> y_max: maximum y after homography for all of the frames\n",
    "    \"\"\"\n",
    "    H = compute_H_to_450()\n",
    "    [x_min, y_min, x_max, y_max] = corners_homography(get_img('VideoFramesLowRes/' + str(1).zfill(3) +'.jpg'),\n",
    "                                                        H[0, :, :])\n",
    "    for i in range(1, NUM_FRAMES):\n",
    "        a = corners_homography(get_img('VideoFramesLowRes/' + str(i+1).zfill(3) +'.jpg'),\n",
    "                                                        H[i, :, :])\n",
    "        x_min = min(x_min, a[0])\n",
    "        y_min = min(y_min, a[1])\n",
    "        x_max = max(x_max, a[2])\n",
    "        y_max = max(y_max, a[3])\n",
    "\n",
    "    return H, x_min, y_min, x_max, y_max\n",
    "\n",
    "def key_frames_corners_homography():\n",
    "    \"\"\"\n",
    "    computing corers and homography for 5 key frames\n",
    "    computing the minimum and maximum coordinates for all of the key frames\n",
    "    after homography to the reference image 450\n",
    "\n",
    "    Inputs:\n",
    "    --> Nothing\n",
    "    Outputs:\n",
    "    ==> key_frames: the list of 5 key frames\n",
    "    ==> H: the 5*3*3 array of homography\n",
    "    ==> x_min: minimum of x\n",
    "    ==> y_min: minimum of y\n",
    "    ==> x_max: maximum of x\n",
    "    ==> y_max: maximum of y\n",
    "    \"\"\"\n",
    "    H = np.zeros((5, 3, 3))\n",
    "    key_frames, H[0, :, :], H[1, :, :], H[2, :, :], H[3, :, :], H[4, :, :] = compute_key_frames_H()\n",
    "    [x_min, y_min, x_max, y_max] = corners_homography(key_frames[0], H[0, :, :])\n",
    "\n",
    "    for i in range(1, 5):\n",
    "        a = corners_homography(key_frames[i],H[i, :, :])\n",
    "        x_min = min(x_min, a[0])\n",
    "        y_min = min(y_min, a[1])\n",
    "        x_max = max(x_max, a[2])\n",
    "        y_max = max(y_max, a[3])\n",
    "\n",
    "    return key_frames, H, x_min, y_min, x_max, y_max\n",
    "\n",
    "def panorama_key_frames(img1, img2):\n",
    "    \"\"\"\n",
    "    computing the panorama of two images\n",
    "    we use a squared difference matrix of two images for computing a value as cost\n",
    "    first we find the union of two images, we crop the pixels of the union part and\n",
    "    make a cost matrix of that size\n",
    "    for this purpose I initialized the first line of the union then used dp algorithm\n",
    "    for computing the cost matrix\n",
    "    by this approach, I found the path with the lowest cost between two images\n",
    "    and used the pixels of the first image for the right side of the panorama and\n",
    "    the pixels of the second image for the left side\n",
    "\n",
    "    Inputs:\n",
    "    --> img1: the first desired image (base one)\n",
    "    --> img2: the second desired image\n",
    "    Outputs:\n",
    "    ==> out_img: the panorama of two images\n",
    "    \"\"\"\n",
    "\n",
    "    [fr1, fr2] = [img1.copy(), img2.copy()]\n",
    "    mask = np.zeros(img1.shape)\n",
    "    diff = np.sum(((img1 - img2)/100) * ((img1 - img2)/100), axis=2)\n",
    "\n",
    "    # making the union matrix\n",
    "    img1[np.any(img1 != [0, 0, 0], axis=-1)] = [1, 1, 1]\n",
    "    img2[np.any(img2 != [0, 0, 0], axis=-1)] = [1, 1, 1]\n",
    "\n",
    "    union = img1 * img2\n",
    "\n",
    "    # computing the cost matrix for the union part\n",
    "    (x, y, _) = np.nonzero(union)\n",
    "    [x_min, y_min, x_max, y_max] = [min(x), min(y), max(x), max(y)]\n",
    "    cropped_img = np.ones((x_max-x_min, y_max-y_min)) * np.inf\n",
    "\n",
    "    # initialization\n",
    "    for i in range(cropped_img.shape[1]):\n",
    "        for j in range(cropped_img.shape[0]):\n",
    "            if union[x_min + j, y_min + i, 0] == 1:\n",
    "                if j < cropped_img.shape[0] / 4:\n",
    "                    cropped_img[j, i] = diff[x_min + j, y_min + i]\n",
    "                break\n",
    "    # computing cost\n",
    "    for i in range(1, cropped_img.shape[0]):\n",
    "        for j in range(1, cropped_img.shape[1]-1):\n",
    "            m = min(cropped_img[i-1, j-1], cropped_img[i-1, j], cropped_img[i-1, j+1])\n",
    "            if m != np.inf:\n",
    "                cropped_img[i, j] = diff[x_min + i, y_min + j] + m\n",
    "    # omitting the last rows of the matrix\n",
    "    for i in range(cropped_img.shape[1]-1, 0, -1):\n",
    "        for j in range(cropped_img.shape[0]-1, 0, -1):\n",
    "            if union[x_min + j, y_min + i, 0] == 1:\n",
    "                if j > 3 * cropped_img.shape[0] / 4:\n",
    "                    cropped_img[j, i] = np.inf\n",
    "                break\n",
    "            else:\n",
    "                cropped_img[j, i] = np.inf\n",
    "\n",
    "    # finding the path between two parts of panorama\n",
    "    val = np.inf\n",
    "    for i in range(cropped_img.shape[1]-1, 0, -1):\n",
    "        for j in range(cropped_img.shape[0]-1, 0, -1):\n",
    "            if cropped_img[j, i] != np.inf:\n",
    "                if j > 3 * cropped_img.shape[0] / 4:\n",
    "                    if cropped_img[j, i] < val:\n",
    "                        [x, y, val] = [j+x_min, i+y_min, cropped_img[j, i]]\n",
    "                break\n",
    "\n",
    "    # computing the mask\n",
    "    for i in range(img1.shape[0]-1, x-1, -1):\n",
    "        for j in range(y):\n",
    "            mask[i, j, :] = [1, 1, 1]\n",
    "\n",
    "    while x > 0 and y > 0 and cropped_img[x-x_min, y-y_min] != np.inf:\n",
    "        m = min(cropped_img[x-1-x_min, y-1-y_min],\n",
    "                cropped_img[x-1-x_min, y-y_min],\n",
    "                cropped_img[x-1-x_min, y+1-y_min])\n",
    "        if m == cropped_img[x-1-x_min, y-1-y_min]:\n",
    "            [x, y] = [x-1, y-1]\n",
    "        elif m == cropped_img[x-1-x_min, y-y_min]:\n",
    "            [x, y] = [x-1, y]\n",
    "        else:\n",
    "            [x, y] = [x-1, y+1]\n",
    "        for j in range(y):\n",
    "            mask[x, j, :] = [1, 1, 1]\n",
    "\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            mask[i, j, :] = [1, 1, 1]\n",
    "\n",
    "    out_img = mask * fr1 + (1-mask) * fr2\n",
    "\n",
    "    return out_img\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=yellow>Main Part Functions</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "def p1(flag=False):\n",
    "    \"\"\"\n",
    "    part one\n",
    "    drawing a red rectangle and then applying the H inverse,\n",
    "    after that making a bigger matrix and first put the 900 frame and then 450\n",
    "    on that.\n",
    "\n",
    "    Inputs:\n",
    "    --> flag: if true saving results, else plotting\n",
    "    Outputs:\n",
    "    ==> Nothing, just saving or plotting results\n",
    "    \"\"\"\n",
    "    img1 = get_img('VideoFrames/450.jpg')\n",
    "    img2 = get_img('VideoFrames/270.jpg')\n",
    "    H = find_homography(img1, img2)\n",
    "    H_inv = np.linalg.inv(H)\n",
    "\n",
    "    points = [(500, 500), (1000, 500), (1000, 1000), (500, 1000)]\n",
    "    out_points = []\n",
    "    color = (255,0,0)\n",
    "    thickness = 5\n",
    "\n",
    "    img1_new = img1.copy()\n",
    "    img2_new = img2.copy()\n",
    "\n",
    "    img1_new = cv2.rectangle(img1_new, points[0], points[2], color, thickness)\n",
    "\n",
    "    for i in range(len(points)):\n",
    "        p = np.array([[points[i][0], points[i][1], 1]]).transpose()\n",
    "        m = np.matmul(H_inv, p)\n",
    "        out_points.append((int(m[0] / m[2]), int(m[1] / m[2])))\n",
    "\n",
    "    for i in range(len(out_points)):\n",
    "        img2_new = cv2.line(img2_new, out_points[i], out_points[(i+1)%4], color, thickness)\n",
    "\n",
    "    img = panorama_two_images(img1, img2, H)\n",
    "\n",
    "    if flag:\n",
    "        save_img(img1_new, 'res01-450-rect.jpg')\n",
    "        save_img(img2_new, 'res02-270-rect.jpg')\n",
    "        save_img(img, 'res03-270-450-panorama.jpg')\n",
    "    else:\n",
    "        plot_img(img1_new)\n",
    "        plot_img(img2_new)\n",
    "        plot_img(img)\n",
    "\n",
    "def p2(flag=False):\n",
    "    \"\"\"\n",
    "    part two\n",
    "    I explained my approach in the functions used below,\n",
    "    just as a short review, I moved all the 5 key frames to the reference frame\n",
    "    which was 450, and then used a dp algorithm to merge them.\n",
    "\n",
    "    Inputs:\n",
    "    --> flag: if true saving results, else plotting\n",
    "    Outputs:\n",
    "    ==> Nothing, just saving or plotting results\n",
    "    \"\"\"\n",
    "    key_frames, H, x_min, y_min, x_max, y_max = key_frames_corners_homography()\n",
    "    [x_offset, y_offset] = [-x_min, -y_min]\n",
    "    (x_size, y_size) = (x_max-x_min, y_max-y_min)\n",
    "    offset = np.array([[1, 0, x_offset], [0, 1, y_offset], [0, 0, 1]])\n",
    "    homography_frames = [cv2.warpPerspective(key_frames[i], np.dot(offset, H[i, :, :]), (x_size, y_size))\n",
    "                         for i in range(5)]\n",
    "\n",
    "    full_image = homography_frames[0]\n",
    "    for i in range(1, 5):\n",
    "        full_image = panorama_key_frames(full_image.copy(), homography_frames[i].copy())\n",
    "\n",
    "    if flag:\n",
    "        save_img(full_image, 'res04-key-frames-panorama.jpg')\n",
    "    else:\n",
    "        plot_img(full_image)\n",
    "\n",
    "def p3():\n",
    "    \"\"\"\n",
    "    part three\n",
    "    here I easily apply the H matrix to each frame using a same offset\n",
    "    computed before and write the frames in batches on the video.\n",
    "    pay attention that open-cv consider images in BGR not RGB, so before writing\n",
    "    we should consider this fact.\n",
    "\n",
    "    Inputs:\n",
    "    --> Nothing\n",
    "    Outputs:\n",
    "    ==> Nothing, just saving the panorama video\n",
    "    \"\"\"\n",
    "    H, x_min, y_min, x_max, y_max = video_corners_homography()\n",
    "    [x_offset, y_offset] = [-x_min, -y_min]\n",
    "    size = (x_max-x_min, y_max-y_min)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter('res05-reference-plane.mp4', fourcc, 30, size)\n",
    "    frames = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(NUM_FRAMES)):\n",
    "        img = get_img('VideoFramesLowRes/' + str(i+1).zfill(3) +'.jpg')\n",
    "        offset = np.array([[1, 0, x_offset], [0, 1, y_offset], [0, 0, 1]])\n",
    "        frame = cv2.warpPerspective(img, np.dot(offset, H[i,:,:]), size)\n",
    "        frames.append(frame)\n",
    "        if (i+1) % 30 == 0:\n",
    "            for j in range(30):\n",
    "                video.write(cv2.cvtColor(frames[j], cv2.COLOR_RGB2BGR))\n",
    "            frames = []\n",
    "\n",
    "    video.release()\n",
    "\n",
    "def p4(flag= False):\n",
    "    \"\"\"\n",
    "    part four\n",
    "    I used the mode for computing the value of background pixels\n",
    "    but the RAM of the laptop does not let us to directly compute the mode for all of\n",
    "    the pixels of an image,\n",
    "    so I made some batches and computed mode for them.\n",
    "    for RAM 8, 100 is a good value for running and for RAM 12 250 works correctly.\n",
    "    with this approach and computing mode for RGB separately, we see a lot of black pixels\n",
    "    in the corners than happens because of camera moving.\n",
    "    to solve this I take a sum of RGB and consider all the values less than a special threshold\n",
    "    like 40 as black pixels and remove them from mode computing. now we have a better background\n",
    "    image in the corners.\n",
    "\n",
    "    but how do I remove black pixels from the mode:\n",
    "    we know that all the images have the values from 0 to 255, so for each black point\n",
    "    in an image I assigned a value more than 255 and different from others to black pixels\n",
    "    and now because of the difference we are sure that the mode is not any of these pixels.\n",
    "\n",
    "    Inputs:\n",
    "    --> flag: if true saving results, else plotting\n",
    "    Outputs:\n",
    "    ==> Nothing, just saving or plotting results\n",
    "    \"\"\"\n",
    "\n",
    "    batch = 100\n",
    "    thresh = 40\n",
    "    frame = get_img('HomographyFrames/' + str(1).zfill(3) +'.jpg')\n",
    "    frames = np.zeros((NUM_FRAMES, frame.shape[0], batch, 3))\n",
    "\n",
    "    background_img = np.zeros(frame.shape)\n",
    "\n",
    "    for j in tqdm.tqdm(range(0, frame.shape[1]-batch, batch)):\n",
    "        temp = np.zeros((frame.shape[0], batch, 3)) + 256\n",
    "        for i in range(NUM_FRAMES):\n",
    "            frame = get_img('HomographyFrames/' + str(i+1).zfill(3) +'.jpg')\n",
    "            a = frame[:, j:j+batch, :]\n",
    "            s = np.sum(a, axis=2)\n",
    "            s = s < thresh\n",
    "            (x, y) = np.nonzero(s)\n",
    "            a[x, y, :] = temp[x, y, :]\n",
    "            temp[x, y, :] = temp[x, y, :] + 1\n",
    "            frames[i, :, :, :] = a\n",
    "        background_img[:, j:j+batch, :] = stats.mode(frames, axis=0).mode\n",
    "\n",
    "    # the last batch\n",
    "    frames = np.zeros((NUM_FRAMES, frame.shape[0], frame.shape[1] % batch , 3))\n",
    "    j = int(frame.shape[1] / batch) * batch\n",
    "    temp = np.zeros((frame.shape[0], frame.shape[1] % batch, 3)) + 256\n",
    "    for i in range(NUM_FRAMES):\n",
    "        frame = get_img('HomographyFrames/' + str(i+1).zfill(3) +'.jpg')\n",
    "        a = frame[:, j:, :]\n",
    "        s = np.sum(a, axis=2)\n",
    "        s = s < thresh\n",
    "        (x, y) = np.nonzero(s)\n",
    "        a[x, y, :] = temp[x, y, :]\n",
    "        temp[x, y, :] = temp[x, y, :] + 1\n",
    "        frames[i, :, :, :] = a\n",
    "    background_img[:, j:, :] = stats.mode(frames, axis=0).mode\n",
    "\n",
    "    if flag:\n",
    "        save_img(background_img, 'res06-background-panorama.jpg')\n",
    "    else:\n",
    "        plot_img(background_img)\n",
    "\n",
    "def p5():\n",
    "    \"\"\"\n",
    "    part five\n",
    "\n",
    "    I applied the inverse of the offset matrix computed before multiplied to H\n",
    "    with the warp perspective on the background image for different frames\n",
    "    I used the frame size of the extracted video for the size of the current video\n",
    "\n",
    "    Inputs:\n",
    "    --> Nothing\n",
    "    Outputs:\n",
    "    ==> Nothing, just saving the background video\n",
    "    \"\"\"\n",
    "    H, x_min, y_min, x_max, y_max = video_corners_homography()\n",
    "    [x_offset, y_offset] = [-x_min, -y_min]\n",
    "    img = get_img('VideoFramesLowRes/' + str(1).zfill(3) +'.jpg')\n",
    "    vid_size = (img.shape[1], img.shape[0])\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter('res07-background-video.mp4', fourcc, 30, vid_size)\n",
    "    frames = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(NUM_FRAMES)):\n",
    "        img = get_img('res06-background-panorama.jpg')\n",
    "        offset = np.array([[1, 0, x_offset], [0, 1, y_offset], [0, 0, 1]])\n",
    "        frame = cv2.warpPerspective(img, np.linalg.inv(np.dot(offset, H[i,:,:])), vid_size)\n",
    "        frames.append(frame)\n",
    "        if (i+1) % 30 == 0:\n",
    "            for j in range(30):\n",
    "                video.write(cv2.cvtColor(frames[j], cv2.COLOR_RGB2BGR))\n",
    "            frames = []\n",
    "\n",
    "    video.release()\n",
    "\n",
    "def p6():\n",
    "    \"\"\"\n",
    "    part six\n",
    "    first I load the original image and the background,\n",
    "    then I make a difference matrix same as the previous parts using norm 2,\n",
    "    here some individual points have big differences so I used a uniform filter\n",
    "    to solve this problem,\n",
    "    after that I normalize the difference matrix and use a threshold for emphasizing\n",
    "    the points which are the foregrounds.\n",
    "    now we should make the explained points red by adding 100 to their R and clipping\n",
    "    them to 255.\n",
    "    at last write the frames in batches on the video in a loop.\n",
    "\n",
    "    Inputs:\n",
    "    --> Nothing\n",
    "    Outputs:\n",
    "    ==> Nothing, just saving the video\n",
    "    \"\"\"\n",
    "    img = get_img('VideoFramesLowRes/' + str(1).zfill(3) +'.jpg')\n",
    "    vid_size = (img.shape[1], img.shape[0])\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter('res08-foreground-video.mp4', fourcc, 30, vid_size)\n",
    "    frames = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(NUM_FRAMES)):\n",
    "        img1 = get_img('VideoFramesLowRes/' + str(i+1).zfill(3) +'.jpg').astype(np.float16)\n",
    "        img2 = get_img('BackgroundFrames/' + str(i+1).zfill(3) +'.jpg').astype(np.float16)\n",
    "        diff = np.sum(((img1 - img2)/100) * ((img1 - img2)/100), axis=2)\n",
    "        diff = nd.uniform_filter(diff.astype(np.uint8), size=15, mode='constant')\n",
    "        diff = (diff - np.min(diff)) / (np.max(diff) - np.min(diff))\n",
    "        diff = diff > 0.01\n",
    "        frame = img1.copy()\n",
    "        frame[:, :, 0] = np.clip(frame[:, :, 0] + 100*diff, 0, 255)\n",
    "        frames.append(frame.astype(np.uint8))\n",
    "        if (i+1) % 30 == 0:\n",
    "            for j in range(30):\n",
    "                video.write(cv2.cvtColor(frames[j], cv2.COLOR_RGB2BGR))\n",
    "            frames = []\n",
    "\n",
    "    video.release()\n",
    "\n",
    "def p7():\n",
    "    \"\"\"\n",
    "    part seven\n",
    "    I increased the video size by multiplying the x size of the image to 1.5\n",
    "    in the warp perspective.\n",
    "    pay attention that when we make the video wider, in the last frames of the 30sec video\n",
    "    we will see a part of the video black, because we do not have any data in the frames\n",
    "    for that part\n",
    "    so I removed the frames after 630 that did not give us any useful data\n",
    "    our final video now is around 21secs.\n",
    "\n",
    "    Inputs:\n",
    "    --> Nothing\n",
    "    Outputs:\n",
    "    ==> Nothing, just saving the wided background video\n",
    "    \"\"\"\n",
    "    H, x_min, y_min, x_max, y_max = video_corners_homography()\n",
    "    [x_offset, y_offset] = [-x_min, -y_min]\n",
    "    img = get_img('VideoFramesLowRes/' + str(1).zfill(3) +'.jpg')\n",
    "    vid_size = (int(img.shape[1]*1.5), img.shape[0])\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter('res09-background-video-wider.mp4', fourcc, 30, vid_size)\n",
    "    frames = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(630)):\n",
    "        img = get_img('res06-background-panorama.jpg')\n",
    "        offset = np.array([[1, 0, x_offset], [0, 1, y_offset], [0, 0, 1]])\n",
    "        frame = cv2.warpPerspective(img, np.linalg.inv(np.dot(offset, H[i,:,:])), vid_size)\n",
    "        frames.append(frame)\n",
    "        if (i+1) % 30 == 0:\n",
    "            for j in range(30):\n",
    "                video.write(cv2.cvtColor(frames[j], cv2.COLOR_RGB2BGR))\n",
    "            frames = []\n",
    "\n",
    "    video.release()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=yellow>Main Part</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "capture_frames('video.mp4', 'VideoFrames')\n",
    "capture_frames_low_res()\n",
    "p1(True)\n",
    "# p2(True)\n",
    "# p3()\n",
    "# capture_frames('res05-reference-plane.mp4', 'HomographyFrames')\n",
    "# p4(True)\n",
    "# p5()\n",
    "# capture_frames('res07-background-video.mp4', 'BackgroundFrames')\n",
    "# p6()\n",
    "# p7()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}